
seed: &seed 3407
batch_size: &batch_size 1024
n_micro_batch: &n_micro_batch 1

n_class: &n_class 5
n_epochs: &n_epochs 10000
weight_decay: &weight_decay 1.0e-5


phases: [train, test]
info_step: 500
is_plot: False
disable_tb: True
disable_tqdm: False
metrics: [loss, t1_acc, t2_acc, g_norm, p_norm]
metrics_print: [loss, t1_acc, t2_acc, g_norm, p_norm]


setup:
  model: Mixer-S-4
  MoE: MoE-2-4-2-8
  FiLM: FiLM-4-4
  head: MLP-S-1
  model_name: Nominal
  optimizer: adam
  lr_scheduler: constant_schedule
  loss: cb_bce_loss
  dataset: nominal
  n_class: *n_class
  seed: *seed
  n_epochs: *n_epochs
  workdir: result
  mixed_precision: False
  smooth_label: null
  weight_decay: *weight_decay
  n_micro_batch: *n_micro_batch

mp_policy: 
  nonfinite: True
  init_val: 32768 #2**15


optimizer:
  opts:
    clip_by_global_norm: {max_norm: 1.0}
  radam: {b1: 0.90, b2: 0.999}
  adam: {b1: 0.90, b2: 0.999}

lr_scheduler:
  warmup_cosine_decay_schedule: 
    init_value: 1.0e-4
    peak_value: 1.0e-2
    warmup_steps: 5
    decay_steps: *n_epochs
    end_value: 1.0e-6
  linear_schedule:
    init_value: 1.0e-4
    end_value: 1.0e-6
    transition_steps: *n_epochs
    transition_begin: 0
  constant_schedule:
    value: 1.0e-4

loss:
  cb_bce_loss: {beta: 0.9999, gamma: 2.0}
  cb_ce_loss: {beta: 0.9999, gamma: 0.5}
  ce_loss: None

dataset:
  data_name: nominal
  batch_size: *batch_size
  split: 
    N: 50
    idx: 1
  n_prefetch: 4
  transpose: True
  cache: True
  prop_table: [4, 5]
  label_table: [5, 3, 3, 2, 1, 0, 4] # [None, d, u, s, c, b, g]
input:
  image_shape: [32, 32, 5]
  prop_shape: [2]

#FiLM : &FiLM {depth: 64, dim: 4, dim_inner: 4, norm: null, activation: null, dropout: null}
FiLM : &FiLM null




hparams:
  weight_decay: *weight_decay
  setup: [loss, model, lr_scheduler, optimizer]
  
head:
  MLP-S-1: {model: MLP, depth:  1, dim:  32, expansion: 4, dropout: 0.1, drop_path: null, layer_scale: null, n_classes: *n_class}
  MLP-S-4: {model: MLP, depth:  4, dim:  32, expansion: 4, dropout: 0.1, drop_path: null, layer_scale: null, n_classes: *n_class}
  MLP-S-8: {model: MLP, depth:  8, dim:  32, expansion: 4, dropout: 0.1, drop_path: null, layer_scale: null, n_classes: *n_class}
  MLP-M-1: {model: MLP, depth:  1, dim:  64, expansion: 4, dropout: 0.1, drop_path: null, layer_scale: null, n_classes: *n_class}
  MLP-M-4: {model: MLP, depth:  4, dim:  64, expansion: 4, dropout: 0.1, drop_path: null, layer_scale: null, n_classes: *n_class}
  MLP-M-8: {model: MLP, depth:  8, dim:  64, expansion: 4, dropout: 0.1, drop_path: null, layer_scale: null, n_classes: *n_class}
  MLP-L-1: {model: MLP, depth:  1, dim: 128, expansion: 4, dropout: 0.1, drop_path: null, layer_scale: null, n_classes: *n_class}
  MLP-L-4: {model: MLP, depth:  4, dim: 128, expansion: 4, dropout: 0.1, drop_path: null, layer_scale: null, n_classes: *n_class}
  MLP-L-8: {model: MLP, depth:  8, dim: 128, expansion: 4, dropout: 0.1, drop_path: null, layer_scale: null, n_classes: *n_class}
  MLP-VL-1:  {model: MLP, depth:  4, dim: 256, expansion: 4, dropout: 0.1, drop_path: null, layer_scale: null, n_classes: *n_class}
  MLP-VVL-1: {model: MLP, depth:  4, dim: 512, expansion: 4, dropout: 0.1, drop_path: null, layer_scale: null, n_classes: *n_class}

MoE: 
  None: null
  Token-MoE-2-4-2-8:  {type: token, cycle: 2, n_experts:  4, topK: 2, capacity:  8, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Token-MoE-2-4-1-1:  {type: token, cycle: 2, n_experts:  4, topK: 1, capacity:  1, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Token-MoE-2-4-1-4:  {type: token, cycle: 2, n_experts:  4, topK: 1, capacity:  4, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Token-MoE-2-4-1-8:  {type: token, cycle: 2, n_experts:  4, topK: 2, capacity:  8, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Token-MoE-2-4-1-16: {type: token, cycle: 2, n_experts:  4, topK: 1, capacity: 16, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Token-MoE-2-5-1-16: {type: token, cycle: 2, n_experts:  5, topK: 1, capacity: 16, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Token-MoE-2-5-1-4:  {type: token, cycle: 2, n_experts:  5, topK: 1, capacity:  4, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Token-MoE-2-4-4-32: {type: token, cycle: 2, n_experts:  4, topK: 4, capacity: 32, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Token-MoE-2-6-2-8:  {type: token, cycle: 2, n_experts:  4, topK: 2, capacity:  8, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Token-MoE-2-8-2-8:  {type: token, cycle: 2, n_experts:  4, topK: 2, capacity:  8, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Image-MoE-2-4-1:    {type: image, cycle: 2, n_experts:  4, topK: 1, capacity: -1, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Image-MoE-2-8-1:    {type: image, cycle: 2, n_experts:  8, topK: 1, capacity: -1, loss_weights: {imp: 1.0e-2, load: 0.0} }
  Image-MoE-2-16-1:   {type: image, cycle: 2, n_experts: 16, topK: 1, capacity: -1, loss_weights: {imp: 1.0e-2, load: 0.0} }

FiLM:
  None: null
  FiLM-4-4:   {depth:  4, dim:  4, dim_inner:  8, norm: null, activation: null, dropout: null}
  FiLM-4-8:   {depth:  8, dim:  4, dim_inner:  8, norm: null, activation: null, dropout: null}
  FiLM-4-16:  {depth: 16, dim:  4, dim_inner:  8, norm: null, activation: null, dropout: null}
  FiLM-4-32:  {depth: 32, dim:  4, dim_inner:  8, norm: null, activation: null, dropout: null}
  FiLM-8-32:  {depth: 32, dim:  8, dim_inner: 16, norm: null, activation: null, dropout: null}
  FiLM-16-32: {depth: 32, dim: 16, dim_inner: 32, norm: null, activation: null, dropout: null}
  FiLM-8-128:  {depth: 128, dim:  8, dim_inner: 16, norm: null, activation: True, dropout: 0.1}
  FiLM-8-128v2:  {depth: 128, dim:  8, dim_inner: 16, norm: null, activation: null, dropout: null}

model:
  gMLP-S:  {patch_size: 4, depth:  4, dim:   32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, n_classes: *n_class}
  gMLP-M:  {patch_size: 4, depth:  8, dim:   64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, n_classes: *n_class}
  gMLP-L:  {patch_size: 4, depth: 16, dim:  128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, n_classes: *n_class}
  
  CNN-64: {dim: 64, depth: 4, patch_size: 16, n_classes: *n_class}
  Test: {dim: 20, depth: 4, patch_size: 16, n_classes: *n_class}
  
  GoB-S-2:  {model: GoB,   patch_size: 4, depth:  2, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  GoB-S-4:  {model: GoB,   patch_size: 4, depth:  4, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  GoB-S-8:  {model: GoB,   patch_size: 4, depth:  8, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  
  ViT-S-4:  {model: ViT,   patch_size: 4, depth:  4, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, qkv_bias: False}
  ViT-S-8:  {model: ViT,   patch_size: 4, depth:  8, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, qkv_bias: False}
  ViT-S-16: {model: ViT,   patch_size: 4, depth: 16, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, qkv_bias: False}
  ViT-M-4:  {model: ViT,   patch_size: 4, depth:  4, dim:  64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, qkv_bias: False}
  ViT-M-8:  {model: ViT,   patch_size: 4, depth:  8, dim:  64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, qkv_bias: False}
  ViT-M-16: {model: ViT,   patch_size: 4, depth: 16, dim:  64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, qkv_bias: False}
  ViT-L-4:  {model: ViT,   patch_size: 4, depth:  4, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, qkv_bias: False}
  ViT-L-8:  {model: ViT,   patch_size: 4, depth:  8, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, qkv_bias: False}
  ViT-L-16: {model: ViT,   patch_size: 4, depth: 16, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null, qkv_bias: False}
  
  
  Mixer-S-4-2: {model: Mixer, patch_size: 2, depth:  4, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-S-4:   {model: Mixer, patch_size: 4, depth:  4, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-S-8:   {model: Mixer, patch_size: 4, depth:  8, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-S-16:  {model: Mixer, patch_size: 4, depth: 16, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-M-4:   {model: Mixer, patch_size: 4, depth:  4, dim:  64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-M-8:   {model: Mixer, patch_size: 4, depth:  8, dim:  64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-M-8-2: {model: Mixer, patch_size: 2, depth:  8, dim:  64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-M-16:  {model: Mixer, patch_size: 4, depth: 16, dim:  64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-L-4:   {model: Mixer, patch_size: 4, depth:  4, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-L-8:   {model: Mixer, patch_size: 4, depth:  8, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-L-16:  {model: Mixer, patch_size: 4, depth: 16, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-L-32:  {model: Mixer, patch_size: 4, depth: 32, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-L-64:  {model: Mixer, patch_size: 4, depth: 64, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-VL-4:  {model: Mixer, patch_size: 4, depth:  4, dim: 256, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}
  Mixer-VVL-4: {model: Mixer, patch_size: 4, depth:  4, dim: 512, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: null}

















