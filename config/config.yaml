
seed: &seed 3407
batch_size: &batch_size 1024
n_micro_batch: &n_micro_batch 1

n_class: &n_class 6
n_epochs: &n_epochs 2
weight_decay: &weight_decay 1.0e-5


phases: [train, test]
info_step: 100
is_plot: False
disable_tb: True
disable_tqdm: False
metrics: [loss, top1_acc, top2_acc, grad_norm, param_norm]


setup:
  model: ViT-MoE-S
  model_name: Nominal
  optimizer: adam
  lr_scheduler: linear_schedule
  loss: ce_loss
  dataset: nominal
  n_class: *n_class
  seed: *seed
  n_epochs: *n_epochs
  workdir: result
  mixed_precision: False
  smooth_label: null
  weight_decay: *weight_decay
  n_micro_batch: *n_micro_batch

mp_policy: 
  nonfinite: True
  init_val: 32768 #2**15


optimizer:
  opts:
    clip_by_global_norm: {max_norm: 1.0}
  radam: {b1: 0.90, b2: 0.999}
  adam: {b1: 0.90, b2: 0.999}

lr_scheduler:
  warmup_cosine_decay_schedule: 
    init_value: 1.0e-4
    peak_value: 1.0e-2
    warmup_steps: 5
    decay_steps: *n_epochs
    end_value: 1.0e-6
  linear_schedule:
    init_value: 1.0e-3
    end_value: 1.0e-6
    transition_steps: *n_epochs
    transition_begin: 0

loss:
  cb_ce_loss: {beta: 0.9999, gamma: null}
  ce_loss: None

dataset:
  data_name: nominal
  batch_size: *batch_size
  split: 
    N: 50
    idx: 1
  n_prefetch: 4
  transpose: True
  cache: True
  prop_table: [0, 4, 5]
  label_table: [7, 1, 2, 3, 4, 5, 0] # [None, d, u, s, c, b, g]
  
#FiLM : &FiLM {depth: 64, dim: 4, dim_inner: 4, norm: null, activation: null, dropout: null}
FiLM : &FiLM null

input:
  image_shape: [32, 32, 5]
  prop_shape: [3]

MoE: &MoE {n_experts: 8, capacity: 4, loss_weights: {'imp': 0.5, 'load': 0.5} }

hparams:
  weight_decay: *weight_decay
  setup: [loss, model, lr_scheduler, optimizer]


model:
  gMLP-S:  {patch_size: 4, depth:  4, dim:   32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class}
  gMLP-M:  {patch_size: 4, depth:  8, dim:   64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class}
  gMLP-L:  {patch_size: 4, depth: 16, dim:  128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class}
  
  CNN-64: {dim: 64, depth: 4, patch_size: 16, n_classes: *n_class}
  Test: {dim: 20, depth: 4, patch_size: 16, n_classes: *n_class}

  ViT-MoE-S: {model: ViT,   patch_size: 4, depth:  4, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: 2, qkv_bias: False, n_experts: 6, topK: 1, capacity: 4, loss_weights: {'imp': 0.05, 'load': 0.05} }
  ViT-MoE-M: {model: ViT,   patch_size: 4, depth:  8, dim:  64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: 2, qkv_bias: False, n_experts: 8, topK: 1, capacity: 4, loss_weights: {'imp': 0.05, 'load': 0.05} }
  ViT-MoE-L: {model: ViT,   patch_size: 4, depth: 16, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: 2, qkv_bias: False, n_experts: 8, topK: 1, capacity: 4, loss_weights: {'imp': 0.5, 'load': 0.5} }
  ViT-S:     {model: ViT,   patch_size: 4, depth:  4, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: null, qkv_bias: False}
  ViT-M:     {model: ViT,   patch_size: 4, depth:  8, dim:  64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: null, qkv_bias: False}
  ViT-L:     {model: ViT,   patch_size: 4, depth: 16, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: null, qkv_bias: False}
  
  Mixer-MoE-S: {model: Mixer, patch_size: 4, depth:  4, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: 2, n_experts: 8, topK: 1, capacity: 4, loss_weights: {'imp': 0.5, 'load': 0.5} }
  Mixer-MoE-M: {model: Mixer, patch_size: 4, depth:  8, dim:  64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: 2, n_experts: 8, topK: 1, capacity: 4, loss_weights: {'imp': 0.5, 'load': 0.5} }
  Mixer-MoE-L: {model: Mixer, patch_size: 4, depth: 16, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: 2, n_experts: 8, topK: 1, capacity: 4, loss_weights: {'imp': 0.5, 'load': 0.5} }
  Mixer-S:     {model: Mixer, patch_size: 4, depth:  4, dim:  32, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: null}
  Mixer-M:     {model: Mixer, patch_size: 4, depth:  8, dim:  64, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: null}
  Mixer-L:     {model: Mixer, patch_size: 4, depth: 16, dim: 128, expansion: 4, n_heads:  4, dropout:  0.1, drop_path:  0.1, layer_scale: 1.0e-5, n_classes: *n_class, moe_cycle: null}

















